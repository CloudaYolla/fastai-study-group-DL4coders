{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#------------STARTING POINT---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker\n",
      "Version: 2.39.1\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: None\n",
      "License: Apache License 2.0\n",
      "Location: /usr/local/lib/python3.7/site-packages\n",
      "Requires: google-pasta, importlib-metadata, packaging, numpy, boto3, attrs, smdebug-rulesconfig, pandas, protobuf3-to-dict, pathos, protobuf\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show  sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 s, sys: 5.86 s, total: 41.9 s\n",
      "Wall time: 7min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import os \n",
    "import urllib.request\n",
    "import boto3\n",
    "\n",
    "#Download and Unzip\n",
    "# !wget https://yourDatasource\n",
    "# !unzip https://yourdatasource.zip\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "# bucket = sagemaker.Session().default_bucket()\n",
    "bucket = \"prj-ml\"\n",
    "\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "\n",
    "def upload_to_s3(channel, Path):\n",
    "    s3_path_to_data = sagemaker.Session().upload_data(bucket=bucket, \n",
    "                                                  path=Path, \n",
    "                                                  key_prefix=channel)\n",
    "\n",
    "# data copy to s3\n",
    "s3_train_key = \"chest-xray-img-classfcn-full-training/train\"\n",
    "s3_validation_key = \"chest-xray-img-classfcn-full-training/validation\"\n",
    "s3_train = 's3://{}/{}/'.format(bucket, s3_train_key)\n",
    "s3_validation = 's3://{}/{}/'.format(bucket, s3_validation_key)\n",
    "\n",
    "\n",
    "upload_to_s3(s3_train_key, './chest_xray/train/')\n",
    "\n",
    "upload_to_s3(s3_validation_key, './chest_xray/val/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"[YOUR ROLE]\"\n",
    "\n",
    "\n",
    "bucket = \"prj-ml\"\n",
    "key = \"chest-xray-img-classfcn-full-training\"\n",
    "key_output = \"output\"                   # Path from the bucket's root to the dataset\n",
    "train_instance_type='ml.m5.large'      # The type of EC2 instance which will be used for training\n",
    "deploy_instance_type='ml.m5.large'     # The type of EC2 instance which will be used for deployment\n",
    "hyperparameters={\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"decay\": 1e-6\n",
    "}\n",
    "\n",
    "train_input_path = \"s3://{}/{}/train/\".format(bucket, key)\n",
    "validation_input_path = \"s3://{}/{}/validation/\".format(bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_spot_instances=True\n",
    "train_max_run=3600\n",
    "train_max_wait = 3600 if train_use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "2021-05-09 21:21:06 Starting - Starting the training job...\n",
      "2021-05-09 21:21:29 Starting - Launching requested ML instancesProfilerReport-1620595265: InProgress\n",
      "......\n",
      "2021-05-09 21:22:29 Starting - Preparing the instances for training......\n",
      "2021-05-09 21:23:30 Downloading - Downloading input data......\n",
      "2021-05-09 21:24:30 Training - Downloading the training image..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mFound 5216 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mFound 16 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.512074 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.542777 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.554837 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.584932 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.585292 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-09 21:24:50.726717: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.759737 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:24:50.819219 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-09 21:24:50 Training - Training image download completed. Training in progress.\u001b[34mDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "    8192/94653016 [..............................] - ETA: 1s\n",
      " 3366912/94653016 [>.............................] - ETA: 1s\u001b[0m\n",
      "\u001b[34m15392768/94653016 [===>..........................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m17784832/94653016 [====>.........................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m24166400/94653016 [======>.......................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m34144256/94653016 [=========>....................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m35635200/94653016 [==========>...................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m45793280/94653016 [=============>................] - ETA: 0s\u001b[0m\n",
      "\u001b[34m50708480/94653016 [===============>..............] - ETA: 0s\u001b[0m\n",
      "\u001b[34m55902208/94653016 [================>.............] - ETA: 0s\u001b[0m\n",
      "\u001b[34m60915712/94653016 [==================>...........] - ETA: 0s\u001b[0m\n",
      "\u001b[34m66027520/94653016 [===================>..........] - ETA: 0s\u001b[0m\n",
      "\u001b[34m71008256/94653016 [=====================>........] - ETA: 0s\u001b[0m\n",
      "\u001b[34m76038144/94653016 [=======================>......] - ETA: 0s\u001b[0m\n",
      "\u001b[34m80773120/94653016 [========================>.....] - ETA: 0s\u001b[0m\n",
      "\u001b[34m85983232/94653016 [==========================>...] - ETA: 0s\u001b[0m\n",
      "\u001b[34m91037696/94653016 [===========================>..] - ETA: 0s\u001b[0m\n",
      "\u001b[34m94658560/94653016 [==============================] - 1s 0us/step\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mresnet50 (Model)             (None, 2048)              23587712  \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 2)                 4098      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 23,591,810\u001b[0m\n",
      "\u001b[34mTrainable params: 4,098\u001b[0m\n",
      "\u001b[34mNon-trainable params: 23,587,712\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mNone\u001b[0m\n",
      "\u001b[34mW0509 21:25:07.752859 139867971155712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0509 21:25:07.865212 139867971155712 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 20:33 - loss: 0.5695 - acc: 0.7800\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 13:27 - loss: 0.5731 - acc: 0.7650\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 10:44 - loss: 0.5854 - acc: 0.7600\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 9:24 - loss: 0.5545 - acc: 0.7700 \u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 8:29 - loss: 0.5240 - acc: 0.7840\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 8:06 - loss: 0.4996 - acc: 0.7967\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 7:35 - loss: 0.4739 - acc: 0.8071\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 7:10 - loss: 0.4557 - acc: 0.8125\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 6:49 - loss: 0.4293 - acc: 0.8256\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 6:30 - loss: 0.4119 - acc: 0.8300\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 6:13 - loss: 0.3861 - acc: 0.8436\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 5:59 - loss: 0.3696 - acc: 0.8492\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 5:44 - loss: 0.3574 - acc: 0.8538\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 5:37 - loss: 0.3466 - acc: 0.8614\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 5:25 - loss: 0.3320 - acc: 0.8687\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 5:14 - loss: 0.3248 - acc: 0.8700\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 5:02 - loss: 0.3223 - acc: 0.8718\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:51 - loss: 0.3192 - acc: 0.8733\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 4:40 - loss: 0.3108 - acc: 0.8763\u001b[0m\n",
      "\u001b[34m20/53 [==========>...................] - ETA: 4:30 - loss: 0.3021 - acc: 0.8800\u001b[0m\n",
      "\u001b[34m21/53 [==========>...................] - ETA: 4:20 - loss: 0.2996 - acc: 0.8790\u001b[0m\n",
      "\u001b[34m22/53 [===========>..................] - ETA: 4:13 - loss: 0.2948 - acc: 0.8805\u001b[0m\n",
      "\u001b[34m23/53 [============>.................] - ETA: 4:04 - loss: 0.2896 - acc: 0.8822\u001b[0m\n",
      "\u001b[34m24/53 [============>.................] - ETA: 3:54 - loss: 0.2890 - acc: 0.8821\u001b[0m\n",
      "\u001b[34m25/53 [=============>................] - ETA: 3:45 - loss: 0.2828 - acc: 0.8848\u001b[0m\n",
      "\u001b[34m26/53 [=============>................] - ETA: 3:36 - loss: 0.2796 - acc: 0.8854\u001b[0m\n",
      "\u001b[34m27/53 [==============>...............] - ETA: 3:27 - loss: 0.2748 - acc: 0.8870\u001b[0m\n",
      "\u001b[34m28/53 [==============>...............] - ETA: 3:18 - loss: 0.2694 - acc: 0.8900\u001b[0m\n",
      "\u001b[34m29/53 [===============>..............] - ETA: 3:10 - loss: 0.2689 - acc: 0.8903\u001b[0m\n",
      "\u001b[34m30/53 [===============>..............] - ETA: 3:02 - loss: 0.2664 - acc: 0.8917\u001b[0m\n",
      "\u001b[34m31/53 [================>.............] - ETA: 2:54 - loss: 0.2642 - acc: 0.8923\u001b[0m\n",
      "\u001b[34m32/53 [=================>............] - ETA: 2:45 - loss: 0.2610 - acc: 0.8934\u001b[0m\n",
      "\u001b[34m33/53 [=================>............] - ETA: 2:37 - loss: 0.2589 - acc: 0.8942\u001b[0m\n",
      "\u001b[34m34/53 [==================>...........] - ETA: 2:29 - loss: 0.2572 - acc: 0.8950\u001b[0m\n",
      "\u001b[34m35/53 [==================>...........] - ETA: 2:20 - loss: 0.2536 - acc: 0.8960\u001b[0m\n",
      "\u001b[34m36/53 [===================>..........] - ETA: 2:12 - loss: 0.2494 - acc: 0.8975\u001b[0m\n",
      "\u001b[34m37/53 [===================>..........] - ETA: 2:04 - loss: 0.2475 - acc: 0.8986\u001b[0m\n",
      "\u001b[34m38/53 [====================>.........] - ETA: 1:56 - loss: 0.2452 - acc: 0.9000\u001b[0m\n",
      "\u001b[34m39/53 [=====================>........] - ETA: 1:49 - loss: 0.2420 - acc: 0.9010\u001b[0m\n",
      "\u001b[34m40/53 [=====================>........] - ETA: 1:41 - loss: 0.2379 - acc: 0.9028\u001b[0m\n",
      "\u001b[34m41/53 [======================>.......] - ETA: 1:33 - loss: 0.2367 - acc: 0.9027\u001b[0m\n",
      "\u001b[34m42/53 [======================>.......] - ETA: 1:25 - loss: 0.2360 - acc: 0.9029\u001b[0m\n",
      "\u001b[34m43/53 [=======================>......] - ETA: 1:17 - loss: 0.2351 - acc: 0.9026\u001b[0m\n",
      "\u001b[34m44/53 [=======================>......] - ETA: 1:09 - loss: 0.2327 - acc: 0.9036\u001b[0m\n",
      "\u001b[34m45/53 [========================>.....] - ETA: 1:01 - loss: 0.2300 - acc: 0.9051\u001b[0m\n",
      "\u001b[34m46/53 [=========================>....] - ETA: 53s - loss: 0.2271 - acc: 0.9063 \u001b[0m\n",
      "\u001b[34m47/53 [=========================>....] - ETA: 46s - loss: 0.2265 - acc: 0.9070\u001b[0m\n",
      "\u001b[34m48/53 [==========================>...] - ETA: 38s - loss: 0.2235 - acc: 0.9083\u001b[0m\n",
      "\u001b[34m49/53 [==========================>...] - ETA: 30s - loss: 0.2225 - acc: 0.9092\u001b[0m\n",
      "\u001b[34m50/53 [===========================>..] - ETA: 23s - loss: 0.2205 - acc: 0.9100\u001b[0m\n",
      "\u001b[34m51/53 [===========================>..] - ETA: 15s - loss: 0.2182 - acc: 0.9108\u001b[0m\n",
      "\u001b[34m52/53 [============================>.] - ETA: 7s - loss: 0.2171 - acc: 0.9110 \u001b[0m\n",
      "\u001b[34m53/53 [==============================] - 405s 8s/step - loss: 0.2144 - acc: 0.9126 - val_loss: 2.6904 - val_acc: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m 1/53 [..............................] - ETA: 5:58 - loss: 0.1313 - acc: 0.9300\u001b[0m\n",
      "\u001b[34m 2/53 [>.............................] - ETA: 6:39 - loss: 0.1487 - acc: 0.9350\u001b[0m\n",
      "\u001b[34m 3/53 [>.............................] - ETA: 6:26 - loss: 0.1303 - acc: 0.9467\u001b[0m\n",
      "\u001b[34m 4/53 [=>............................] - ETA: 6:16 - loss: 0.1257 - acc: 0.9475\u001b[0m\n",
      "\u001b[34m 5/53 [=>............................] - ETA: 6:02 - loss: 0.1224 - acc: 0.9540\u001b[0m\n",
      "\u001b[34m 6/53 [==>...........................] - ETA: 5:52 - loss: 0.1264 - acc: 0.9567\u001b[0m\n",
      "\u001b[34m 7/53 [==>...........................] - ETA: 5:42 - loss: 0.1189 - acc: 0.9614\u001b[0m\n",
      "\u001b[34m 8/53 [===>..........................] - ETA: 5:32 - loss: 0.1194 - acc: 0.9563\u001b[0m\n",
      "\u001b[34m 9/53 [====>.........................] - ETA: 5:23 - loss: 0.1181 - acc: 0.9556\u001b[0m\n",
      "\u001b[34m10/53 [====>.........................] - ETA: 5:21 - loss: 0.1168 - acc: 0.9550\u001b[0m\n",
      "\u001b[34m11/53 [=====>........................] - ETA: 5:14 - loss: 0.1186 - acc: 0.9536\u001b[0m\n",
      "\u001b[34m12/53 [=====>........................] - ETA: 5:05 - loss: 0.1215 - acc: 0.9517\u001b[0m\n",
      "\u001b[34m13/53 [======>.......................] - ETA: 4:56 - loss: 0.1231 - acc: 0.9508\u001b[0m\n",
      "\u001b[34m14/53 [======>.......................] - ETA: 4:49 - loss: 0.1238 - acc: 0.9514\u001b[0m\n",
      "\u001b[34m15/53 [=======>......................] - ETA: 4:40 - loss: 0.1220 - acc: 0.9520\u001b[0m\n",
      "\u001b[34m16/53 [========>.....................] - ETA: 4:32 - loss: 0.1213 - acc: 0.9525\u001b[0m\n",
      "\u001b[34m17/53 [========>.....................] - ETA: 4:23 - loss: 0.1217 - acc: 0.9524\u001b[0m\n",
      "\u001b[34m18/53 [=========>....................] - ETA: 4:16 - loss: 0.1215 - acc: 0.9522\u001b[0m\n",
      "\u001b[34m19/53 [=========>....................] - ETA: 4:11 - loss: 0.1251 - acc: 0.9505\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(\n",
    "  entry_point=\"model.py\",             # Your entry script\n",
    "  role=role,\n",
    "  framework_version=\"1.14.0\",               # TensorFlow's version\n",
    "  hyperparameters=hyperparameters,\n",
    "  training_steps=100,\n",
    "  evaluation_steps=100,\n",
    "  instance_count=1,                   # \"The number of GPUs instances to use\"\n",
    "  instance_type=train_instance_type,\n",
    "  use_spot_instances=train_use_spot_instances,  \n",
    "  max_run=train_max_run,\n",
    "  max_wait=train_max_wait,\n",
    "  py_version=\"py3\",  # now required    \n",
    ")\n",
    "\n",
    "print(\"Training ...\")\n",
    "estimator.fit({'training': train_input_path, 'validation': validation_input_path})\n",
    "\n",
    "print(\"Deploying ...\")\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=deploy_instance_type)\n",
    "\n",
    "print(\"Predictor endpoint name : %s\" % predictor.endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-1.15-cpu-py37-ubuntu18.04-v7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
