{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBA PA3\n",
    "\n",
    "French version: https://github.com/Daniel-R-Armstrong/French-Wiki-2500-Pretrained-SentencePiece-LM/blob/master/fr_spm.ipynb\n",
    "https://forums.fast.ai/t/sentencepiece/53010/50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish ULMFiT from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide\n",
    "# !pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install fastai==1.0.61 #This right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install fastcore==1. #This right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fastai v1 API: https://fastai1.fast.ai/overview.html\n",
    "# from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.utils import *\n",
    "# show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print ('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/ec2-user/.fastai/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "torch.cuda.set_device(2)\n",
    "# data_path = Config.data_path()\n",
    "# data_path = '/home/ec2-user/.fastai/data'\n",
    "\n",
    "lang = 'tr'\n",
    "name = f'{lang}wiki'\n",
    "path = data_path/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_path = path/'models'\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [mdl_path/f'{lang}_wt', mdl_path/f'{lang}_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/.fastai/data/trwiki')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish wikipedia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HBA\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install wikiextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikiextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils import split_wiki,get_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompress wiki file from cli\n",
    "\n",
    "Source: https://github.com/attardi/wikiextractor\n",
    "\n",
    "1. Do `python setup.py install`\n",
    "1. Double check with: `which wikiextractor`\n",
    "\n",
    "`\n",
    "base) [ec2-user@ip-172-16-69-8 trwiki]$ which wikiextractor\n",
    "~/anaconda3/bin/wikiextractor\n",
    "`\n",
    "\n",
    "1. Uncrompress\n",
    "\n",
    "`\n",
    "(base) [ec2-user@ip-172-16-69-8 trwiki]$ python -m wikiextractor.WikiExtractor trwiki-latest-pages-articles.xml\n",
    "INFO: 2832129   Mucize Dünyası: New York – Birleşik Kahramanlar\n",
    "INFO: 2832111   Kraliyet Mühendislik Akademisi üyesi kadınlar listesi\n",
    "INFO: 2832131   Ilana Rovina\n",
    "INFO: 2832155   Artur Taymazov\n",
    "INFO: 2832130   Enka (kadın voleybol takımı) 1992-93 sezonu\n",
    "INFO: Finished 31-process extraction of 377951 articles in 123.1s (3071.5 art/s)\n",
    "INFO: total of page: 732729, total of articl page: 377951; total of used articl page: 377951\n",
    "(base) [ec2-user@ip-172-16-69-8 trwiki]$ which wikiextractor\n",
    "~/anaconda3/bin/wikiextractor\n",
    "`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading...\n",
      "unzipping...\n",
      "extracting... akirmak\n"
     ]
    }
   ],
   "source": [
    "get_wiki(path,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc id=\"10\" url=\"https://tr.wikipedia.org/wiki?curid=10\" title=\"Cengiz Han\">\r\n",
      "Cengiz Han\r\n",
      "\r\n",
      "Cengiz Han (doğum Temuçin, – 18 Ağustos 1227) ölümünden sonra tarihin en büyük yüzölçümüne sahip imparatorluğu haline gelmiş Moğol İmparatorluğu'nun kurucusu ve ilk Kağanı ve İmparatoru olan Moğol komutan ve hükümdar. 13. Yüzyılın başında Orta Asya'daki tüm göçebe bozkır kavimlerini birleştirerek bir ulus hâline getirdi ve o ulusu \"Moğol\" siyasi kimliği çatısı altında topladı.\r\n"
     ]
    }
   ],
   "source": [
    "# from nlputils import split_wiki,get_wiki\n",
    "\n",
    "# get_wiki(path,lang)\n",
    "!head -n4 {path}/{name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n"
     ]
    }
   ],
   "source": [
    "dest = split_wiki(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turkish is an [Agglutinative_language](https://en.wikipedia.org/wiki/Agglutinative_language) so it needs special care!\n",
    "\n",
    "![Turkish morphemes example](images/turkish.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBA fix\n",
    "\n",
    "1. Open via: `vi ~/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py`\n",
    "1. see: https://forums.fast.ai/t/multifit-runtime-error-permission-denied/72874/5\n",
    "1. See: https://github.com/fastai/fastai/issues/2572 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class 'fastai.text.data.SPProcessor'>: it's not the same object as fastai.text.data.SPProcessor\n"
     ]
    }
   ],
   "source": [
    "data = (TextList.from_folder(dest, processor=[OpenFileProcessor(), SPProcessor()])\n",
    "        .split_by_rand_pct(0.1, seed=42)\n",
    "        .label_for_lm()\n",
    "        .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data.save(f'{lang}_databunch')\n",
    "len(data.vocab.itos),len(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(dest, f'{lang}_databunch', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data, AWD_LSTM, drop_mult=0.1, wd=0.1, pretrained=False).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "lr *= bs/48  # Scale learning rate by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32().save(lm_fns[0], with_opt=False)\n",
    "learn.data.vocab.save(lm_fns[1].with_suffix('.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.win.tue.nl/~mpechen/projects/smm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clas = path/'movies'\n",
    "path_clas.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (path_clas/'tr_polarity.pos').open(encoding='iso-8859-9').readlines()\n",
    "pos_df = pd.DataFrame({'text':pos})\n",
    "pos_df['pos'] = 1\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = (path_clas/'tr_polarity.neg').open(encoding='iso-8859-9').readlines()\n",
    "neg_df = pd.DataFrame({'text':neg})\n",
    "neg_df['pos'] = 0\n",
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pos_df,neg_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(df, path_clas, cols='text', processor=SPProcessor.load(dest))\n",
    "    .split_by_rand_pct(0.1, seed=42)\n",
    "    .label_for_lm()           \n",
    "    .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data_lm.save(f'{lang}_clas_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path_clas, f'{lang}_clas_databunch', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, pretrained_fnames=lm_fns, drop_mult=1.0, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(5, slice(lr/10,lr*10), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save(f'{lang}fine_tuned')\n",
    "learn_lm.save_encoder(f'{lang}fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(df, path_clas, cols='text', processor=SPProcessor.load(dest))\n",
    "    .split_by_rand_pct(0.1, seed=42)\n",
    "    .label_from_df(cols='pos')\n",
    "    .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, pretrained=False, wd=0.1).to_fp16()\n",
    "learn_c.load_encoder(f'{lang}fine_tuned_enc')\n",
    "learn_c.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-2\n",
    "lr *= bs/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.freeze_to(-2)\n",
    "learn_c.fit_one_cycle(2, slice(lr/(2.6**4),lr), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.freeze_to(-3)\n",
    "learn_c.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.unfreeze()\n",
    "learn_c.fit_one_cycle(4, slice(lr/10/(2.6**4),lr/10), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy in Gezici (2018), *Sentiment Analysis in Turkish* is: `75.16%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.save(f'{lang}clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
