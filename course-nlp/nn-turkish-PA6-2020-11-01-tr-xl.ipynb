{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBA PA5\n",
    "\n",
    "French version: https://github.com/Daniel-R-Armstrong/French-Wiki-2500-Pretrained-SentencePiece-LM/blob/master/fr_spm.ipynb\n",
    "https://forums.fast.ai/t/sentencepiece/53010/50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish ULMFiT from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide\n",
    "# !pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HBA: TextList is in fastaiv1\n",
    "https://fastai1.fast.ai/text.data.html#TextList.from_folder\n",
    "https://docs.fast.ai/text.data#TextBlock.from_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai==1.0.61 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (1.0.61)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.1.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.6.0)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (7.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (4.9.3)\n",
      "Requirement already satisfied: bottleneck in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.3.2)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (7.352.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.5.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (2.24.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (0.7.0)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (3.3.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (0.7)\n",
      "Requirement already satisfied: numexpr in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (2.7.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (20.4)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (5.3.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from fastai==1.0.61) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from pandas->fastai==1.0.61) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from pandas->fastai==1.0.61) (2.8.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from torch>=1.0.0->fastai==1.0.61) (0.18.2)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from beautifulsoup4->fastai==1.0.61) (2.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from requests->fastai==1.0.61) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from requests->fastai==1.0.61) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from requests->fastai==1.0.61) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from requests->fastai==1.0.61) (2.10)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (7.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (4.49.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (49.6.0.post20200814)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from matplotlib->fastai==1.0.61) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from matplotlib->fastai==1.0.61) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from matplotlib->fastai==1.0.61) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from packaging->fastai==1.0.61) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install fastai==1.0.61 #This right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install fastcore==1. #This right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fastai v1 API: https://fastai1.fast.ai/overview.html\n",
    "# from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.utils import *\n",
    "# show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/ec2-user/.fastai/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "# torch.cuda.set_device(0)\n",
    "# data_path = Config.data_path()\n",
    "# data_path = '/home/ec2-user/.fastai/data'\n",
    "\n",
    "lang = 'tr'\n",
    "name = f'{lang}wiki'\n",
    "path = data_path/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_path = path/'models'\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "lm_fns = [mdl_path/f'{lang}_wt', mdl_path/f'{lang}_wt_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/.fastai/data/trwiki')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish wikipedia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HBA\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install wikiextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikiextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils import split_wiki,get_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompress wiki file from cli\n",
    "\n",
    "Source: https://github.com/attardi/wikiextractor\n",
    "\n",
    "1. Do `python setup.py install`\n",
    "1. Double check with: `which wikiextractor`\n",
    "\n",
    "`\n",
    "base) [ec2-user@ip-172-16-69-8 trwiki]$ which wikiextractor\n",
    "~/anaconda3/bin/wikiextractor\n",
    "`\n",
    "\n",
    "1. Uncrompress\n",
    "\n",
    "`\n",
    "(base) [ec2-user@ip-172-16-69-8 trwiki]$ python -m wikiextractor.WikiExtractor trwiki-latest-pages-articles.xml\n",
    "INFO: 2832129   Mucize Dünyası: New York – Birleşik Kahramanlar\n",
    "INFO: 2832111   Kraliyet Mühendislik Akademisi üyesi kadınlar listesi\n",
    "INFO: 2832131   Ilana Rovina\n",
    "INFO: 2832155   Artur Taymazov\n",
    "INFO: 2832130   Enka (kadın voleybol takımı) 1992-93 sezonu\n",
    "INFO: Finished 31-process extraction of 377951 articles in 123.1s (3071.5 art/s)\n",
    "INFO: total of page: 732729, total of articl page: 377951; total of used articl page: 377951\n",
    "(base) [ec2-user@ip-172-16-69-8 trwiki]$ which wikiextractor\n",
    "~/anaconda3/bin/wikiextractor\n",
    "`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.fastai/data/trwiki/trwiki already exists; not downloading\n"
     ]
    }
   ],
   "source": [
    "get_wiki(path,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc id=\"10\" url=\"https://tr.wikipedia.org/wiki?curid=10\" title=\"Cengiz Han\">\r\n",
      "Cengiz Han\r\n",
      "\r\n",
      "Cengiz Han (doğum Temuçin, – 18 Ağustos 1227) ölümünden sonra tarihin en büyük yüzölçümüne sahip imparatorluğu haline gelmiş Moğol İmparatorluğu'nun kurucusu ve ilk Kağanı ve İmparatoru olan Moğol komutan ve hükümdar. 13. Yüzyılın başında Orta Asya'daki tüm göçebe bozkır kavimlerini birleştirerek bir ulus hâline getirdi ve o ulusu \"Moğol\" siyasi kimliği çatısı altında topladı.\r\n"
     ]
    }
   ],
   "source": [
    "# from nlputils import split_wiki,get_wiki\n",
    "\n",
    "# get_wiki(path,lang)\n",
    "!head -n4 {path}/{name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ec2-user/.fastai/data/trwiki/trwiki-latest-pages-articles.xml.bz2'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/wikiextractor-orig'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/trwiki-latest-pages-articles.xml'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/log'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/wikiextractor'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/docs'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/trwiki'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/models')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.fastai/data/trwiki/docs already exists; not splitting\n"
     ]
    }
   ],
   "source": [
    "dest = split_wiki(path,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ec2-user/.fastai/data/trwiki/docs/Kara delik.txt'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/docs/Heaviside katmanı.txt'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/docs/Zurna.txt'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/docs/Özallı Yıllar.txt'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/docs/Kuşça, Cihanbeyli.txt')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest.ls()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/.fastai/data/trwiki/docs')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turkish is an [Agglutinative_language](https://en.wikipedia.org/wiki/Agglutinative_language) so it needs special care!\n",
    "\n",
    "![Turkish morphemes example](images/turkish.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBA fix\n",
    "\n",
    "1. Open via: `vi ~/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py`\n",
    "1. see: https://forums.fast.ai/t/multifit-runtime-error-permission-denied/72874/5\n",
    "1. See: https://github.com/fastai/fastai/issues/2572 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56219\r\n"
     ]
    }
   ],
   "source": [
    "#PRINT NUMBER OF FILES IN DIR\n",
    "!find /home/ec2-user/.fastai/data/trwiki/docs -mindepth 1 -maxdepth 1 -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hba why it takes soo long, 2 hrs to create data\n",
    "https://forums.fast.ai/t/getting-memoryerror-when-trying-to-create-textlist/40261/28\n",
    "\n",
    "Quotes:\n",
    "\n",
    "`\n",
    "Yes there is a high peak of memory usage during the preprocessing, because python sucks at multi-process, so the array with the results is copied across all the processes instead of being shared.\n",
    "To reduce RAM usage, reduce the number of workers (but then it’s going to be slower).\n",
    "`\n",
    "\n",
    "more \n",
    "\n",
    "`\n",
    "Tokenizing the full dataset took about 2 hours.\n",
    "\n",
    "When you were working through yours, did you max out your memory? I’ve found that if you try to tokenize too much at once and you don’t have enough memory to finish the process, it tends to stall and never complete. You might need to try working with a small chunk at a time.\n",
    "`\n",
    "\n",
    "more\n",
    "\n",
    "`\n",
    "It doesn’t always scale linearly when you train on multiple GPUs, so I can’t really say. Training WT103 with the standard AWD_LSTM is roughly 1h-1h30 an epoch IIRC, on a p3 (so a V100).\n",
    "\n",
    "...\n",
    "\n",
    "Ok so I finally got past the tokenization phase and have a databunch in hand!\n",
    "\n",
    "It still took quite a bit of memory (peaked at 345GB of the 624 GB available on n1-highmem-96) but it was at least 2x less memory than the standard way with the default processors (which exhausted the available memory on this instance and crashed) and didn’t seem to take any longer (it didn’t seem to get as “stuck” halfway through either)\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read About TextDataBunch\n",
    "https://fastai1.fast.ai/text.data.html#TextDataBunch\n",
    "\n",
    "### TextData\n",
    "\n",
    "class TextList[source][test]\n",
    "TextList(items:Iterator[T_co], vocab:Vocab=None, pad_idx:int=1, sep=' ', **kwargs) :: ItemList\n",
    "\n",
    "Basic ItemList for text data.\n",
    "\n",
    "vocab contains the correspondence between ids and tokens, pad_idx is the id used for padding. You can pass a custom processor in the kwargs to change the defaults for tokenization or numericalization. It should have the following form:\n",
    "\n",
    "tokenizer = Tokenizer(SpacyTokenizer, 'en')\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(max_vocab=30000)]\n",
    "To use sentencepiece instead of spaCy (requires to install sentencepiece separately) you would pass\n",
    "\n",
    "processor = SPProcessor()\n",
    "\n",
    "### Preprocessor\n",
    "\n",
    "PreProcessor that tokenizes and numericalizes with sentencepiece\n",
    "\n",
    "pre_rules and post_rules default to defaults.text_pre_rules and defaults.text_post_rules respectively, vocab_sz defaults to the minimum between max_vocab_sz and one quarter of the number of words in the training texts (rounded to the nearest multiple of 8). model_type is passed to sentencepiece, so can be unigram (default), bpe, char, or word. Other sentencepiece parameters are langm max_sentence_len and char_coverage (default to 1. for European languages and 0.99 for others).\n",
    "\n",
    "## CPU notes: \n",
    "\n",
    "Some tasks take up to 86GB x 4 = 320 GB. See Trello SS\n",
    "\n",
    "- label_for_lm()\n",
    "- databunch()\n",
    "- fine_tune\n",
    "\n",
    "## Quotes from 2020 NLP NB\n",
    "\n",
    "\"Subword tokenization provides a way to  scale between character tokenization  & word tokenization, & handles every human language without needing language-specific algorithms to be developed. It can even handle genomic sequences or MIDI music!\" #NLP \n",
    "\n",
    "Our special rules tokens appear first, and then every word appears once, in frequency order. The defaults to Numericalize are min_freq=3,max_vocab=60000. max_vocab=60000 results in fastai replacing all words other than the most common 60,000 with a special unknown word token, xxunk. This is useful to avoid having an overly large embedding matrix, since that can slow down training and use up too much memory, and can also mean that there isn't enough data to train useful representations for rare words. However, this last issue is better handled by setting min_freq; the default min_freq=3 means that any word appearing less than three times is replaced with xxunk.\n",
    "\n",
    "fastai can also numericalize your dataset using a vocab that you provide, by passing a list of words as the vocab parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (TextList.from_folder(dest, processor=[OpenFileProcessor(), SPProcessor()])\n",
    "#         .split_by_rand_pct(0.1, seed=42)\n",
    "#         .label_for_lm()\n",
    "#         .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "# data.save(f'{lang}_databunch')\n",
    "# len(data.vocab.itos),len(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = (TextList.from_folder(dest, processor=[OpenFileProcessor(), SPProcessor()])\n",
    "        .split_by_rand_pct(0.1, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py:475: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ds.items = np.array(sum(e.map(self._encode_batch, partition_by_cores(ds.items, self.n_cpus)), []))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tll = tl.label_for_lm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tll.databunch(bs=bs, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(f'{lang}_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 50586)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.vocab.itos),len(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(dest, f'{lang}_databunch', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  idx_min = (t != self.pad_idx).nonzero().min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁nitelen irler . ▁xxmaj ▁kara ▁delikler in , ▁\" teki l lik \" leri ▁dolayısıyla , ▁üç ▁boyutlu ▁olmadıkları , ▁sıfır ▁hacimli ▁oldukları ▁kabul ▁edilir . ▁xxmaj ▁kara de lik lerin ▁içinde ▁zamanın ▁ise ▁yavaş ▁ak tığı ▁veya ▁ak madığı ▁tahmin ▁edilmektedir . ▁xxmaj ▁kara ▁delikler ▁xxmaj ▁einstein ' ın ▁genel ▁görelilik ▁kuramı yla ▁tanımlanmış lardır . ▁xxmaj ▁doğrudan ▁gözlem len eme mekle ▁birlikte , ▁çeşitli ▁dalga ▁boy larını ▁kullanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁xxmaj ▁samsun ▁merkezli ▁xxmaj ▁ a de ka ▁da ▁hâlen ▁faaliyet te dir . ▁xxmaj ▁son ▁yıllarda ▁yapılan ▁yatırım larla ▁birlikte ▁enerji ▁kaynaklarının ▁xxmaj ▁türkiye ' ye ▁giriş ▁kapı larından ▁biri ▁durumuna ▁gelen ▁xxmaj ▁samsun ▁zengin ▁enerji ▁kaynaklarına ▁yakınlığı ▁ve ▁uluslararası ▁ticari ▁ilişkileri yle ▁çok ▁yönlü ▁bir ▁merkez ▁görünüm dedir . ▁xxmaj ▁samsun , ▁2003' te ▁açılan ▁xxmaj ▁mavi ▁xxmaj ▁akım ▁ile ▁birlikte ▁xxmaj ▁rusya ▁doğalgaz ının ▁xxmaj ▁türkiye '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁xxmaj ▁vektör ▁formunda , ▁eğer ▁i , ▁gelen ▁ışın ▁yönünde ▁işaret ▁eden ▁bir ▁birim ▁vektör ▁ise ▁ve ▁ n , ▁yüzey in ▁normal i ▁ise , ▁kır ılan ▁ r ▁ ışını nın ▁yönü ▁şöyledir : ▁[ 3 ] ▁burada ▁ δ ▁aşağıdaki ▁ifade ye ▁eşittir . ▁xxmaj ▁eğer ▁i ▁ · ▁ n ▁&lt; 0 ▁ise ▁hesaplamalar da ▁ - n ▁kullanılmalıdır . ▁ δ ▁&lt; 0 ▁olduğunda ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>şarkıcı ) ▁xxmaj ▁kim ▁xxmaj ▁ki - bu m ▁( doğum ▁23 ▁xxmaj ▁eylül ▁1991 ) ▁ya ▁da ▁daha ▁çok ▁bilinen ▁sahne ▁adıyla ▁xxmaj ▁ key , ▁xxmaj ▁güney ▁xxmaj ▁koreli ▁şarkıcı ▁ve ▁oyuncu dur . ▁shin e e ▁grubunun ▁üyesidir . ▁xxmaj ▁ key , ▁23 ▁xxmaj ▁eylül ▁1991' de ▁xxmaj ▁da e gu , ▁xxmaj ▁güney ▁xxmaj ▁kore ' de ▁doğdu . ▁2006 ▁yılında ▁xxup ▁sm ▁xxmaj ▁entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁xxmaj ▁ayetullah ▁xxmaj ▁ebu ▁el - kasım ▁el - ho y ' un ▁yanında ▁okumak ▁üzere ▁xxmaj ▁irak ' ın ▁xxmaj ▁necef ▁kentine ▁gitmiştir . ▁xxmaj ▁ si stan i , ▁xxmaj ▁irak ▁xxmaj ▁cumhurbaşkanı ▁xxmaj ▁abdul ker im ▁xxmaj ▁kasım ▁yönetimindeki ▁askeri ▁jun ta ▁rejimi ▁döneminde ▁1960 ▁yılında ▁xxmaj ▁tak li d ▁xxmaj ▁ merci i ▁unvanına ▁ulaşmıştır . ▁xxmaj ▁ si stan i ▁henüz ▁31 ▁yaşındayken ▁(19 61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data, AWD_LSTM, drop_mult=0.1, wd=0.1, pretrained=False).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations language model, vocab, databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/ec2-user/SageMaker/fast-nlp/course-nlp/dotfastai-data/trwiki/tmp/spm.model\n",
    "/home/ec2-user/SageMaker/fast-nlp/course-nlp/dotfastai-data/trwiki/tmp/spm.vocab\n",
    "/home/ec2-user/SageMaker/fast-nlp/course-nlp/dotfastai-data/trwiki/docs/tr_databunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Jupyter going idle \n",
    "The default autosave interval in Jupyter notebook is 120 seconds. You can change this with the %autosave magic command for an individual notebook like this:\n",
    "\n",
    "To change it for all of your notebooks, you need to modify the custom.js file.\n",
    "\n",
    "\n",
    "1. Navigate to your jupyter config directory, which you can find by running the following command in the Terminal:\n",
    "\n",
    "jupyter --config-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "lr *= bs/48  # Scale learning rate by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For output of this Training job. See Tweet: \n",
    "\n",
    "- https://twitter.com/HBAkirmak/status/1322256689022775297\n",
    "- https://twitter.com/HBAkirmak/status/1322148506069512193?s=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32().save(lm_fns[0], with_opt=False)\n",
    "learn.data.vocab.save(lm_fns[1].with_suffix('.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32().export('/home/ec2-user/.fastai/data/trwiki/models/learner_modtr_spm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.vocab.save('/home/ec2-user/.fastai/data/trwiki/models/learner_vocab_tr_spm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('/home/ec2-user/.fastai/data/trwiki/models/learner_tr_spm_enc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/.fastai/data/trwiki/models/learner_mod_tr_spm_save.pkl.pth')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().save('/home/ec2-user/.fastai/data/trwiki/models/learner_mod_tr_spm_save.pkl',return_path=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From NN-IMDB NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 50586)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.vocab.itos),len(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ing ▁xxmaj ▁da rt ▁xxmaj ▁operasyonu ' nu ▁başlatma ya ▁karar ▁verdi . ▁xxup ▁abd ▁bombalama sı ▁sırasında ▁hala ▁xxmaj ▁han o i ' de ▁bulunan ▁xxmaj ▁ko si gin ▁ve ▁xxmaj ▁sovyet ▁hükûmeti ▁xxmaj ▁kuzey ▁xxmaj ▁vietnam ' a ▁askeri ▁yardım larını ▁artırma ya ▁karar ▁verdi ▁ve ▁böylece ▁xxmaj ▁kruşçev ' in ▁xxmaj ▁vietnam ' daki ▁politikasının ▁büyük ▁oranda ▁tersine ▁döndüğü ▁dönem ▁başladı . ▁&lt; ▁/ ▁doc &gt; ▁xxbos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>' de ▁okudu . ▁xxup ▁h tv ▁xxmaj ▁wal es ' te ▁yayınlanan ▁\" jac ob ' s ▁xxmaj ▁ la d der \" ▁dizisinde ▁11 ▁yaşında ▁rol ▁aldı ▁ve ▁daha ▁sonra ▁xxmaj ▁royal ▁xxmaj ▁wel sh ▁xxmaj ▁college ▁of ▁xxmaj ▁music ▁&amp; ▁xxmaj ▁drama ' da ▁okumaya ▁başladı ▁ve ▁2008 ▁yılında ▁oradan ▁mezun ▁oldu . ▁xxmaj ▁bar nard , ▁xxmaj ▁şubat ▁2009' da ▁xxmaj ▁tony ▁xxmaj ▁ödülleri ▁ödüllü ▁müzikal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁önce ▁xxmaj ▁timur , ▁deniz ▁kalesi nin ▁yıkılması nı ▁ve ▁daha ▁önce ▁xxmaj ▁türklerin ▁elinde ▁durmuş ▁olan ▁ve ▁ akropol isi ▁koruyan ▁kara ▁kalesi nin ▁güçlendirilmesi ni ▁emretti . ▁xxmaj ▁i ̇ zmir ' in ▁fethi nin ▁akı bet inde ▁xxmaj ▁eski fo ça ' daki ▁xxmaj ▁ceneviz ▁karakolu ▁xxmaj ▁timur ' un ▁torunu ▁xxmaj ▁muhammed ▁xxmaj ▁sultan ▁xxmaj ▁mirza ' nın ▁ordularının ▁tehdidi ▁altındaydı . ▁xxmaj ▁yeni fo ça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁xxmaj ▁bu ▁durumda , ▁her ▁topun ▁tek ▁tek ▁vur u lup ▁imha ▁edilmesi ▁gerekmektedir . ▁xxmaj ▁saldırı ▁gecesi ▁xxmaj ▁osmanlı ▁komutanlığı , ▁xxmaj ▁gelibolu ▁xxmaj ▁yarımadası ' nın ▁batı ▁sahillerinde , ▁olası ▁bir ▁çıkarma ▁hareketine ▁karşı ▁bazı ▁önlemler ▁almıştır . ▁xxmaj ▁bu ▁arada ▁saldırıya ▁uğrayan ▁tabya larda ▁tüm ▁gece ▁boyunca ▁hasar ların ▁giderilmesi ▁için ▁gereken ▁çalışmalar ▁yapıldı , ▁toplar ▁yeniden ▁ateşe ▁hazır ▁hale ▁getirildi . ▁xxmaj ▁boz an ▁hava ▁sebebiyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁geçirdiler ▁ve ▁hükümdar ▁xxmaj ▁hicaz ' a ▁kaçtı . ▁xxmaj ▁ku fe ▁xxmaj ▁mescid inde ▁kürsü ye ▁çıkan ▁xxmaj ▁muhtar , ▁xxmaj ▁ali ' nin ▁adalet ini ▁geri ▁getirmek ▁için ▁mücadelesini ▁sürdü r eceğini ▁açıkladı . ▁xxmaj ▁ay n ' ül ▁xxmaj ▁var da ▁xxmaj ▁muharebesi ▁sonrası ▁ilerleyen ▁xxmaj ▁emevî ▁xxmaj ▁ordusu ▁xxmaj ▁musul ' u ▁aldı ▁ve ▁xxmaj ▁ku fe ' ye ▁ilerledi . ▁xxmaj ▁muhtar , ▁xxmaj ▁yezid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18063"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"wikipedia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_words = set(vocab.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁istekleri',\n",
       " '▁almanya',\n",
       " '▁seçti',\n",
       " '▁ash',\n",
       " '▁kolesterol',\n",
       " 'muyor',\n",
       " '▁yakalanan',\n",
       " '▁tarafının',\n",
       " '▁princeton',\n",
       " 'millî',\n",
       " '▁geride',\n",
       " '▁kiril',\n",
       " 'mog',\n",
       " 'ru',\n",
       " '▁oynanır',\n",
       " '▁radyo',\n",
       " '▁lazio',\n",
       " 'y',\n",
       " '▁kapandı',\n",
       " '▁yeryüzünde',\n",
       " '支',\n",
       " '▁yazılmış',\n",
       " '▁nehri',\n",
       " '▁musikisi',\n",
       " '▁davanın',\n",
       " '▁nazırlığı',\n",
       " '▁boynuzlu',\n",
       " 'dari',\n",
       " '▁ışın',\n",
       " '▁kabilesi',\n",
       " '▁preston',\n",
       " '-6',\n",
       " '▁ettirildi',\n",
       " 'ھ',\n",
       " '▁hizmetine',\n",
       " '▁molla',\n",
       " '▁yarımada',\n",
       " '▁açmıştır',\n",
       " '▁alışık',\n",
       " '苾',\n",
       " '▁butler',\n",
       " 'ಯ',\n",
       " '▁uzan',\n",
       " '▁fosil',\n",
       " '▁pci',\n",
       " '▁microsoft',\n",
       " '字',\n",
       " '▁kullanabilme',\n",
       " '▁skeç',\n",
       " '▁bolu',\n",
       " '▁katerina',\n",
       " '(',\n",
       " '▁belarus',\n",
       " 'lov',\n",
       " '▁benzet',\n",
       " '▁palermo',\n",
       " '▁adapt',\n",
       " '▁müziği',\n",
       " '▁ülker',\n",
       " 'wikipedia',\n",
       " 'ग',\n",
       " '▁yarıçap',\n",
       " '▁yüzyılın',\n",
       " '▁maddenin',\n",
       " '▁bristol',\n",
       " '▁mesajı',\n",
       " '▁yakıp',\n",
       " '▁aktarılması',\n",
       " 'yy',\n",
       " '▁yıktı',\n",
       " '▁okunması',\n",
       " '2,8',\n",
       " '85',\n",
       " '▁kuşu',\n",
       " '▁amaçlayan',\n",
       " '▁düzeneği',\n",
       " 'ayık',\n",
       " '▁çapındaki',\n",
       " '▁izah',\n",
       " '争',\n",
       " 'product',\n",
       " '▁bozunma',\n",
       " 'resmi',\n",
       " 'landırır',\n",
       " 'chor',\n",
       " 'station',\n",
       " '▁kong',\n",
       " '▁korumaktadır',\n",
       " '▁toprak',\n",
       " '▁jersey',\n",
       " '▁çıplak',\n",
       " '▁bırakacak',\n",
       " '▁geçirildiği',\n",
       " '▁tanınmaktadır',\n",
       " '▁manet',\n",
       " 'grin',\n",
       " '▁lotus',\n",
       " '▁görevi',\n",
       " '▁faktörü',\n",
       " 'kincisi',\n",
       " '▁birbiriyle',\n",
       " '▁1997-98',\n",
       " '▁başkanlığındaki',\n",
       " '▁finansman',\n",
       " 'pokémon',\n",
       " 'pu',\n",
       " '▁kalanını',\n",
       " '▁ikili',\n",
       " 'lenmişti',\n",
       " '▁üye',\n",
       " '▁kuruluştur',\n",
       " 'aziz',\n",
       " '▁örf',\n",
       " 'tsch',\n",
       " '▁broşür',\n",
       " 'ܼ',\n",
       " '▁frances',\n",
       " '▁justinus',\n",
       " '藤',\n",
       " 'shu',\n",
       " 'ி',\n",
       " '▁programlar',\n",
       " '▁enjekt',\n",
       " 'ent',\n",
       " '▁raid',\n",
       " '株',\n",
       " '▁gözlemledi',\n",
       " '▁khz',\n",
       " '▁albümde',\n",
       " '▁milyonlarca',\n",
       " '▁yatay',\n",
       " '▁tutulmuş',\n",
       " '▁patenci',\n",
       " '▁denklemin',\n",
       " '▁alması',\n",
       " '单',\n",
       " 'sezon',\n",
       " 'ds',\n",
       " 'leyip',\n",
       " 'oluşturulmasında',\n",
       " '▁balistik',\n",
       " '▁bremen',\n",
       " 'cil',\n",
       " '▁içermesi',\n",
       " '▁yedinci',\n",
       " '▁burdur',\n",
       " 'meye',\n",
       " 'nge',\n",
       " '▁filtreler',\n",
       " '▁konuş',\n",
       " '▁yönlendirme',\n",
       " '▁etçil',\n",
       " '▁yürüttüğü',\n",
       " '▁quo',\n",
       " '▁teksas',\n",
       " '▁afiş',\n",
       " '▁gidip',\n",
       " 'meden',\n",
       " '▁tip',\n",
       " '▁tüneli',\n",
       " '▁15.',\n",
       " 'mona',\n",
       " '▁bulut',\n",
       " 'melidir',\n",
       " '▁konfor',\n",
       " '▁diskografisi',\n",
       " '▁kalibre',\n",
       " '▁meclisin',\n",
       " 'muz',\n",
       " '▁gelmekte',\n",
       " 'tarihlenmektedir',\n",
       " 'zen',\n",
       " '▁hayatına',\n",
       " '▁varmış',\n",
       " '▁başarısızlığı',\n",
       " '▁fatih',\n",
       " '▁sezonundan',\n",
       " '▁kronos',\n",
       " '▁dönemin',\n",
       " '▁modası',\n",
       " '▁pat',\n",
       " '▁başlamasıyla',\n",
       " '▁vita',\n",
       " '▁leke',\n",
       " '▁düşüş',\n",
       " 'kus',\n",
       " '▁tork',\n",
       " '▁uyuşma',\n",
       " '총',\n",
       " '▁yakılması',\n",
       " '▁soğutul',\n",
       " '▁algı',\n",
       " '▁dikkat',\n",
       " '▁sitoplazma',\n",
       " '‟',\n",
       " '▁oluşturmak',\n",
       " 'larla',\n",
       " '▁galata',\n",
       " '▁dolar',\n",
       " '▁meclis',\n",
       " 'gno',\n",
       " 'fresh',\n",
       " '회',\n",
       " '▁bulunacak',\n",
       " '▁makas',\n",
       " '▁1967',\n",
       " '▁röportajlar',\n",
       " '▁yirmi',\n",
       " '▁cauchy',\n",
       " '▁brian',\n",
       " '▁karşılaşıl',\n",
       " 'dedir',\n",
       " '▁diken',\n",
       " '▁amy',\n",
       " '▁öldürüldü',\n",
       " '\"\",',\n",
       " '▁basılan',\n",
       " '▁maksim',\n",
       " 'yat',\n",
       " '▁erwin',\n",
       " '▁nasuh',\n",
       " '▁kıyafetleri',\n",
       " '▁ormanların',\n",
       " '▁görülmemiş',\n",
       " '▁km',\n",
       " '▁fuku',\n",
       " '▁ödüle',\n",
       " '▁dolaşan',\n",
       " '▁kauçuk',\n",
       " '▁uluslar',\n",
       " '▁malik',\n",
       " '虚',\n",
       " 'chrys',\n",
       " '▁rehabilitasyon',\n",
       " '術',\n",
       " '▁hidroliz',\n",
       " '72',\n",
       " '▁1831',\n",
       " 'ging',\n",
       " '▁şüphesiz',\n",
       " '▁magmatik',\n",
       " 'virüs',\n",
       " 'lanabilen',\n",
       " 'tık',\n",
       " 'ĉ',\n",
       " '▁pavlov',\n",
       " '▁market',\n",
       " 'bağı',\n",
       " '▁sahnelenmiştir',\n",
       " '▁kosta',\n",
       " '▁felsefesinde',\n",
       " '▁edebilmek',\n",
       " 'zag',\n",
       " '▁oluşur',\n",
       " '▁saga',\n",
       " '▁grönland',\n",
       " 'chus',\n",
       " '▁baskıları',\n",
       " '▁sınav',\n",
       " '▁dördü',\n",
       " '▁2017',\n",
       " 'skandinavya',\n",
       " '▁nesneleri',\n",
       " '49',\n",
       " '▁gizemli',\n",
       " '▁istikametinde',\n",
       " '▁sorumluluk',\n",
       " '▁kadırga',\n",
       " '▁kurul',\n",
       " '▁iletişimi',\n",
       " '盧',\n",
       " '▁türkmenistan',\n",
       " '▁kulübüne',\n",
       " '▁alfred',\n",
       " '▁tamamladı',\n",
       " 'leşme',\n",
       " '▁etmelerine',\n",
       " '▁sağlayacak',\n",
       " 'yin',\n",
       " '▁darbe',\n",
       " 'õ',\n",
       " '▁ayda',\n",
       " '▁biraz',\n",
       " '▁dans',\n",
       " '▁sokaklar',\n",
       " '▁hemfikir',\n",
       " '▁burhaneddin',\n",
       " '▁mur',\n",
       " '▁rio',\n",
       " 'llah',\n",
       " 'raf',\n",
       " '1909',\n",
       " '▁şerit',\n",
       " '▁indirme',\n",
       " '▁element',\n",
       " '▁önceki',\n",
       " '▁kadrosu',\n",
       " '▁seferber',\n",
       " '▁patlama',\n",
       " '▁bulunması',\n",
       " '▁gösterisi',\n",
       " 'pedal',\n",
       " '▁yürütmüştür',\n",
       " 'aynı',\n",
       " '▁yapı',\n",
       " '▁kaleme',\n",
       " 'ṁ',\n",
       " '▁hedefe',\n",
       " \"▁1917'\",\n",
       " '▁çalışan',\n",
       " 'bükme',\n",
       " '▁sen',\n",
       " '▁rey',\n",
       " '▁bal',\n",
       " '▁sencer',\n",
       " '▁tarihteki',\n",
       " '▁gore',\n",
       " '▁fotoğrafı',\n",
       " '▁kontrolü',\n",
       " '▁oluşturması',\n",
       " '▁partiden',\n",
       " 'bard',\n",
       " '▁duyu',\n",
       " '▁yarar',\n",
       " '▁gsm',\n",
       " '蜜',\n",
       " 'ndy',\n",
       " '▁takıntı',\n",
       " '▁champions',\n",
       " 'alkan',\n",
       " '村',\n",
       " '▁iletilir',\n",
       " 'گ',\n",
       " '▁claudius',\n",
       " '7.3',\n",
       " '▁kavramı',\n",
       " 'verdi',\n",
       " '▁geçirme',\n",
       " '▁sınıflandır',\n",
       " 'ό',\n",
       " '▁1832',\n",
       " '▁dia',\n",
       " '▁anlaşmanın',\n",
       " '▁anımsat',\n",
       " '▁tanısı',\n",
       " 'ière',\n",
       " '▁manyetik',\n",
       " '▁geçtikten',\n",
       " '▁kazı',\n",
       " '▁polen',\n",
       " '▁tüzel',\n",
       " '▁kişiyi',\n",
       " '▁mad',\n",
       " '▁dindar',\n",
       " 'laştırılan',\n",
       " '▁tuval',\n",
       " '▁bilmediği',\n",
       " 'hü',\n",
       " '▁bahse',\n",
       " '▁are',\n",
       " 'n',\n",
       " 'ından',\n",
       " 'uyor',\n",
       " '▁jorge',\n",
       " '▁akışkan',\n",
       " '▁etiket',\n",
       " '▁medeniyetin',\n",
       " '▁edenler',\n",
       " '▁yararına',\n",
       " 'lardır',\n",
       " '▁futbolcusu',\n",
       " '▁eskişehir',\n",
       " '▁finali',\n",
       " '▁keman',\n",
       " '▁marangoz',\n",
       " '▁itunes',\n",
       " 'ӣ',\n",
       " '▁açılı',\n",
       " '▁kötü',\n",
       " '▁sıcak',\n",
       " '▁beyaz',\n",
       " '▁kraliçe',\n",
       " '▁kyoto',\n",
       " '▁temalar',\n",
       " '▁protestocular',\n",
       " '▁milletler',\n",
       " '▁vatanı',\n",
       " 'č',\n",
       " 'lou',\n",
       " '▁beklenen',\n",
       " '▁yaşlanma',\n",
       " '▁üsküdar',\n",
       " 'japonca',\n",
       " '▁snow',\n",
       " '▁karargahı',\n",
       " '▁antibiyotikler',\n",
       " '▁saltanatı',\n",
       " '▁futbolcu',\n",
       " '▁ziyaretçiler',\n",
       " '▁sabun',\n",
       " '▁rektör',\n",
       " '▁kaleci',\n",
       " '▁piskoposluk',\n",
       " '▁burjuvazi',\n",
       " '▁1838',\n",
       " '▁yoğunluğu',\n",
       " '▁koşma',\n",
       " 'dâr',\n",
       " 'fol',\n",
       " 'dikleri',\n",
       " '▁harekât',\n",
       " 'okrat',\n",
       " '▁paolo',\n",
       " '▁yazarken',\n",
       " '隊',\n",
       " '▁girişiminde',\n",
       " '▁arm',\n",
       " '▁malta',\n",
       " 'ϊ',\n",
       " '▁kırmak',\n",
       " '▁uzaklaştırma',\n",
       " '▁önerilmektedir',\n",
       " '▁kuşatan',\n",
       " 'leştirilecek',\n",
       " 'dım',\n",
       " '▁etkisinden',\n",
       " '▁nihat',\n",
       " '▁yağışlı',\n",
       " 'yaklaş',\n",
       " '▁fesh',\n",
       " 'ebildiği',\n",
       " '▁gitgide',\n",
       " '▁istenmeyen',\n",
       " '▁digiturk',\n",
       " '▁nohut',\n",
       " '▁bulutu',\n",
       " '▁altyapısına',\n",
       " '▁kr',\n",
       " 'one',\n",
       " '▁ag',\n",
       " 'sko',\n",
       " '▁sıralama',\n",
       " '▁komedya',\n",
       " '▁istasyon',\n",
       " '▁libya',\n",
       " 'ing',\n",
       " '▁başardılar',\n",
       " '▁çark',\n",
       " '▁abbasiler',\n",
       " '▁farklıdır',\n",
       " '▁bartın',\n",
       " '▁karakolu',\n",
       " '▁soyluları',\n",
       " '▁vakum',\n",
       " '▁memduh',\n",
       " '▁damgasını',\n",
       " '▁altıncı',\n",
       " '▁doc',\n",
       " '▁tövbe',\n",
       " '▁makamı',\n",
       " 'dığı',\n",
       " 'istik',\n",
       " '釜',\n",
       " '▁anlatmak',\n",
       " '▁karmaşa',\n",
       " '▁prag',\n",
       " '▁dillerinde',\n",
       " '▁bmw',\n",
       " '▁nasihat',\n",
       " '▁kışlar',\n",
       " 'stokes',\n",
       " '▁duyurulmuştur',\n",
       " '▁protein',\n",
       " 'domain',\n",
       " '▁oynayacağı',\n",
       " '▁yetkili',\n",
       " '▁optimizasyon',\n",
       " '▁osiris',\n",
       " '▁doktoru',\n",
       " '▁şevki',\n",
       " '▁artmıştır',\n",
       " '▁erozyon',\n",
       " '▁herkes',\n",
       " '▁polat',\n",
       " '▁ağrı',\n",
       " '▁yenilgi',\n",
       " '▁fraksiyon',\n",
       " '▁almaya',\n",
       " '▁1823',\n",
       " '▁vancouver',\n",
       " '-1987',\n",
       " '三',\n",
       " '▁isim',\n",
       " '▁kapağında',\n",
       " '▁rastlanan',\n",
       " 'içi',\n",
       " '▁artrit',\n",
       " '̲',\n",
       " 'larda',\n",
       " '▁ölüm',\n",
       " '▁çekirdeği',\n",
       " '▁civar',\n",
       " '▁görüşleri',\n",
       " '▁hidroksit',\n",
       " '▁şeritli',\n",
       " '▁deresi',\n",
       " '▁işlevler',\n",
       " '▁mexico',\n",
       " '▁ilaçlar',\n",
       " '▁covid',\n",
       " '▁nm',\n",
       " '▁bbc',\n",
       " '▁yararlanma',\n",
       " '▁yapabilmektedir',\n",
       " '▁ferah',\n",
       " '▁çorap',\n",
       " '▁konuştu',\n",
       " '▁varyant',\n",
       " '▁başlangıçta',\n",
       " '▁kuşatmaya',\n",
       " '▁uyuşmazlık',\n",
       " 'ᔪ',\n",
       " '▁çifte',\n",
       " '匈',\n",
       " '▁kalsit',\n",
       " '▁endüstrisi',\n",
       " '▁rudolf',\n",
       " '▁bombardıman',\n",
       " '▁gaziosmanpaşa',\n",
       " '▁konsepti',\n",
       " '▁sy',\n",
       " '▁odak',\n",
       " '▁kurtaran',\n",
       " 'flower',\n",
       " '▁sistem',\n",
       " '▁todd',\n",
       " '태',\n",
       " '▁kışlası',\n",
       " '▁french',\n",
       " 'leşecek',\n",
       " '▁perdelik',\n",
       " '▁1914',\n",
       " '▁söylendi',\n",
       " '▁şarkılar',\n",
       " '▁bulunmuştur',\n",
       " '▁görünümünü',\n",
       " '▁geçince',\n",
       " 'ong',\n",
       " '▁mutluluğu',\n",
       " '▁sürat',\n",
       " '▁ipuçları',\n",
       " 'birçok',\n",
       " '▁yüzyıl',\n",
       " 'hayatım',\n",
       " '▁donna',\n",
       " '▁tasarruf',\n",
       " '▁boyutunu',\n",
       " '▁rowling',\n",
       " '▁yapar',\n",
       " 'xi',\n",
       " '▁dağıtıl',\n",
       " '▁tepeler',\n",
       " '▁içermekteydi',\n",
       " '▁wel',\n",
       " '▁devletleri',\n",
       " '▁teb',\n",
       " '▁crystal',\n",
       " 'pes',\n",
       " '▁saman',\n",
       " '▁düşünsel',\n",
       " '▁bekledi',\n",
       " '▁verecek',\n",
       " '▁collection',\n",
       " '▁carlo',\n",
       " '所',\n",
       " '▁dolby',\n",
       " 'derinden',\n",
       " '▁değme',\n",
       " 'ir',\n",
       " '物',\n",
       " '▁üst',\n",
       " '▁basınç',\n",
       " '▁olasılığı',\n",
       " '▁gücüne',\n",
       " '▁donma',\n",
       " '▁gözünde',\n",
       " '▁yolunda',\n",
       " 'apple',\n",
       " '▁çağdaş',\n",
       " '▁karınca',\n",
       " '▁sci',\n",
       " 'rılmış',\n",
       " '▁tamamlayarak',\n",
       " '▁1985-86',\n",
       " '▁sırrı',\n",
       " 'psi',\n",
       " '▁kültürüne',\n",
       " '▁salzburg',\n",
       " '▁bulunurlar',\n",
       " '▁türlerinden',\n",
       " '▁şiddetli',\n",
       " 'oto',\n",
       " 'balkar',\n",
       " '▁giymeye',\n",
       " 'ق',\n",
       " 'sviçreli',\n",
       " '▁uzağa',\n",
       " '▁üretebilir',\n",
       " '▁battle',\n",
       " '▁karıştı',\n",
       " '▁vücut',\n",
       " '▁bozukluk',\n",
       " '1963',\n",
       " '▁dubai',\n",
       " 'ռ',\n",
       " '▁manto',\n",
       " '▁faruk',\n",
       " '▁sırada',\n",
       " '▁edilebilen',\n",
       " '▁girerken',\n",
       " 'göçer',\n",
       " '▁marjinal',\n",
       " 'yacağı',\n",
       " '▁ezra',\n",
       " 'ス',\n",
       " 'allah',\n",
       " '▁edilmemiştir',\n",
       " '▁kayserispor',\n",
       " '▁suçlarından',\n",
       " '▁başlatılmıştır',\n",
       " '▁etmişti',\n",
       " '▁evinde',\n",
       " '▁octavian',\n",
       " '▁yörüngesi',\n",
       " 'gro',\n",
       " '▁performansı',\n",
       " 'ì',\n",
       " 'abi',\n",
       " '巴',\n",
       " '豊',\n",
       " '心',\n",
       " '▁öldükten',\n",
       " '▁şirketi',\n",
       " '▁duyuru',\n",
       " '▁yalısı',\n",
       " '▁başbakanlığı',\n",
       " '▁aktivite',\n",
       " '▁hazırladı',\n",
       " '▁öncesine',\n",
       " '人',\n",
       " '▁yetişme',\n",
       " '▁duydukları',\n",
       " '▁baltacı',\n",
       " '▁konuları',\n",
       " '▁ürettiği',\n",
       " '▁gine',\n",
       " '▁sharpe',\n",
       " '▁açlık',\n",
       " '▁katarak',\n",
       " '▁yepyeni',\n",
       " '▁takımları',\n",
       " '▁saadet',\n",
       " '▁eşkıya',\n",
       " '相',\n",
       " 'may',\n",
       " 'şbirliği',\n",
       " 'bağımsız',\n",
       " 'tsu',\n",
       " 'æ',\n",
       " '▁ekolü',\n",
       " '▁youtube',\n",
       " 'ö',\n",
       " '▁dalgaların',\n",
       " '▁döndüğünde',\n",
       " 'amayacağı',\n",
       " '▁şirketini',\n",
       " '▁ulaşama',\n",
       " '▁münih',\n",
       " '▁kaşık',\n",
       " 'âb',\n",
       " 'del',\n",
       " '▁vererek',\n",
       " '▁dawn',\n",
       " '▁verimli',\n",
       " '▁way',\n",
       " 'fig',\n",
       " '▁gelişmeleri',\n",
       " 'ө',\n",
       " 'gün',\n",
       " '▁kapsamda',\n",
       " '▁sol',\n",
       " 'sir',\n",
       " '▁sokakta',\n",
       " '井',\n",
       " '▁theodor',\n",
       " '▁kurmaya',\n",
       " '▁beslenme',\n",
       " '▁edebilme',\n",
       " '▁sanayisi',\n",
       " '▁sermayesi',\n",
       " '▁ada',\n",
       " 'park',\n",
       " '▁taraftarları',\n",
       " '▁taraftarı',\n",
       " '▁kurumlarının',\n",
       " '▁helikopter',\n",
       " '▁alerji',\n",
       " '▁taleplerini',\n",
       " '▁mast',\n",
       " '▁noyan',\n",
       " '▁spielberg',\n",
       " 'ianus',\n",
       " '▁bahis',\n",
       " '▁çevreleyen',\n",
       " 'ლ',\n",
       " '▁paketleri',\n",
       " '˩',\n",
       " '▁gönderilecek',\n",
       " '▁yetişmesi',\n",
       " '▁değişkenlik',\n",
       " '▁ressamlar',\n",
       " 'tour',\n",
       " '▁hapis',\n",
       " '▁sabit',\n",
       " '▁savaşmak',\n",
       " '▁aşkını',\n",
       " 'ृ',\n",
       " '▁görünmektedir',\n",
       " '▁thunder',\n",
       " '▁çıkan',\n",
       " 'omer',\n",
       " '▁uzaklaşır',\n",
       " '▁bebek',\n",
       " '▁duyduğu',\n",
       " '▁girişi',\n",
       " '▁savaşmaya',\n",
       " '▁kâmil',\n",
       " '▁sapkın',\n",
       " '單',\n",
       " '▁robin',\n",
       " '▁varsa',\n",
       " '▁sartre',\n",
       " '▁avar',\n",
       " 'çiliği',\n",
       " '▁remzi',\n",
       " '▁bazı',\n",
       " '▁kariyerini',\n",
       " 'que',\n",
       " 'ghost',\n",
       " '▁aids',\n",
       " '▁nakış',\n",
       " '▁senin',\n",
       " ']]',\n",
       " 'gümüş',\n",
       " 'lenebilmesi',\n",
       " 'atta',\n",
       " '▁tur',\n",
       " '3.1',\n",
       " '▁manhattan',\n",
       " 'ນ',\n",
       " '▁korunmak',\n",
       " '▁olmalı',\n",
       " '▁seslendirme',\n",
       " 'cılar',\n",
       " '▁yayımlandı',\n",
       " 'ұ',\n",
       " '▁koza',\n",
       " '▁filmlerinde',\n",
       " 'gus',\n",
       " '▁yozgat',\n",
       " '^',\n",
       " '▁belirgin',\n",
       " 'neill',\n",
       " 'faz',\n",
       " '▁koalisyonu',\n",
       " '▁sekreterlik',\n",
       " '▁şiir',\n",
       " '▁gardiyan',\n",
       " '▁ölçek',\n",
       " '▁18.',\n",
       " '▁athletic',\n",
       " '▁film',\n",
       " '화',\n",
       " '▁kolon',\n",
       " 'otis',\n",
       " '▁dil',\n",
       " '▁nikiforos',\n",
       " '▁ihmal',\n",
       " '▁hafif',\n",
       " '▁dostluk',\n",
       " '▁capitol',\n",
       " '▁hükme',\n",
       " '▁yakalanmış',\n",
       " '▁şarkıda',\n",
       " '▁özdemir',\n",
       " 'ǰ',\n",
       " '▁güvenliğini',\n",
       " '▁alınmasıyla',\n",
       " '▁sürdürebil',\n",
       " 'pozitron',\n",
       " '▁12',\n",
       " 'lmış',\n",
       " '刘',\n",
       " '▁vuruş',\n",
       " '▁bilgin',\n",
       " '▁düzlemin',\n",
       " '▁bölümünde',\n",
       " '▁hastalıklara',\n",
       " 'chi',\n",
       " 'dora',\n",
       " '▁asidin',\n",
       " '▁gig',\n",
       " '8',\n",
       " '▁yapılıyordu',\n",
       " '▁karısını',\n",
       " '▁edilmeleri',\n",
       " '▁indirim',\n",
       " '▁simgeleyen',\n",
       " 'shar',\n",
       " '▁süreyle',\n",
       " 'mereti',\n",
       " '▁biçim',\n",
       " '▁geçiyordu',\n",
       " 'maktadırlar',\n",
       " '▁ocağı',\n",
       " '▁vermesini',\n",
       " '▁sapı',\n",
       " '▁kazakistan',\n",
       " '▁açıklaması',\n",
       " '虎',\n",
       " '▁kavuşması',\n",
       " '▁aktardı',\n",
       " 'web',\n",
       " '▁salah',\n",
       " '▁yaklaşımı',\n",
       " '▁metropol',\n",
       " '▁takımını',\n",
       " '▁konan',\n",
       " '▁oynatıl',\n",
       " '▁seyretme',\n",
       " '▁gayrimüslim',\n",
       " 'aba',\n",
       " '▁verildiğinde',\n",
       " 'gılgamış',\n",
       " '▁kurumsal',\n",
       " '▁biyo',\n",
       " '▁talan',\n",
       " '▁suçlanan',\n",
       " '▁research',\n",
       " 'オ',\n",
       " 'oji',\n",
       " 'rül',\n",
       " '▁taka',\n",
       " '▁pas',\n",
       " '博',\n",
       " '▁seat',\n",
       " 'kill',\n",
       " \"▁1900'\",\n",
       " '▁değişik',\n",
       " '▁kuvvetler',\n",
       " '▁statüsünü',\n",
       " '▁nedensellik',\n",
       " 'ni',\n",
       " '한',\n",
       " '▁vilayeti',\n",
       " '▁yetiştir',\n",
       " 'cent',\n",
       " '▁54',\n",
       " '▁uygarlığı',\n",
       " '▁parçacığın',\n",
       " '▁kanunu',\n",
       " '▁cahil',\n",
       " '▁çocuk',\n",
       " '▁çalışılmıştır',\n",
       " '▁kurmay',\n",
       " '▁oluşumunu',\n",
       " '▁gökyüzü',\n",
       " '▁sheamus',\n",
       " '▁bunun',\n",
       " 'ф',\n",
       " 'ру',\n",
       " '▁fay',\n",
       " '200',\n",
       " '▁alanından',\n",
       " '▁çalıştırmak',\n",
       " '▁devretme',\n",
       " '罗',\n",
       " 'idir',\n",
       " '▁yürütücü',\n",
       " 'џ',\n",
       " '▁bab',\n",
       " '▁çolak',\n",
       " '▁mahal',\n",
       " '▁kaybeden',\n",
       " '▁çavuş',\n",
       " '▁tasarısı',\n",
       " '▁senelik',\n",
       " 'hale',\n",
       " '▁evinin',\n",
       " '▁pub',\n",
       " '▁çekiyor',\n",
       " 'ჟ',\n",
       " '▁yükselti',\n",
       " 'yar',\n",
       " 'doctor',\n",
       " '▁ziyaretçilerin',\n",
       " '▁tazminat',\n",
       " '▁deneme',\n",
       " '▁kayıtlarını',\n",
       " '▁şark',\n",
       " '▁oylamada',\n",
       " '▁başrolde',\n",
       " 'mamoğlu',\n",
       " '▁istiyorlardı',\n",
       " '▁batarya',\n",
       " '▁parçasıdır',\n",
       " '▁elektrolit',\n",
       " '▁görevine',\n",
       " '▁bilimkurgu',\n",
       " '▁çalışıp',\n",
       " 'cağı',\n",
       " '▁japon',\n",
       " 'sw',\n",
       " '▁uzaklaştı',\n",
       " '▁modernize',\n",
       " '▁döndürme',\n",
       " '▁hesaplanması',\n",
       " '▁pro',\n",
       " '▁bakterilerin',\n",
       " '▁analist',\n",
       " 'ölü',\n",
       " '▁dönüşen',\n",
       " '▁antonio',\n",
       " 'lenmekte',\n",
       " '▁reddeder',\n",
       " '▁alexander',\n",
       " '▁yıkama',\n",
       " '▁çevirmiş',\n",
       " '𐰴',\n",
       " '▁çekmek',\n",
       " 'љ',\n",
       " '▁bahsedilmiştir',\n",
       " '▁kaşgar',\n",
       " 'ów',\n",
       " '石',\n",
       " 'ę',\n",
       " '▁ekim',\n",
       " '▁askerî',\n",
       " '▁saatte',\n",
       " '▁uyarılmış',\n",
       " '\\x92',\n",
       " '▁çankırı',\n",
       " '▁yerler',\n",
       " '▁görkemli',\n",
       " '▁hareketlerinin',\n",
       " '₹',\n",
       " '▁yenilgisi',\n",
       " '▁fotoğrafları',\n",
       " '▁sistemiyle',\n",
       " '▁buradaki',\n",
       " '▁tok',\n",
       " '▁165',\n",
       " '▁parlaklık',\n",
       " 'laşarak',\n",
       " 'ε',\n",
       " 'lendirecek',\n",
       " '▁sülale',\n",
       " '▁tanıştı',\n",
       " 'sız',\n",
       " '▁ögeleri',\n",
       " '▁erbakan',\n",
       " '▁malzemelerin',\n",
       " '▁konumda',\n",
       " '▁medeni',\n",
       " 'ک',\n",
       " 'spekt',\n",
       " '▁dimitri',\n",
       " '▁ankaragücü',\n",
       " '愛',\n",
       " '▁west',\n",
       " '▁kurmuşlardır',\n",
       " '▁delikli',\n",
       " '▁modüller',\n",
       " '▁vatandaşlarının',\n",
       " '▁sonrası',\n",
       " '▁gri',\n",
       " 'be',\n",
       " 'captain',\n",
       " '▁genişleme',\n",
       " '▁yetenekleri',\n",
       " '▁telekom',\n",
       " '▁baskılar',\n",
       " 'ogram',\n",
       " '▁mürettebatı',\n",
       " '限',\n",
       " '舱',\n",
       " '▁kaldılar',\n",
       " '▁etek',\n",
       " '▁yığıl',\n",
       " '▁fareler',\n",
       " ...}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"▁nesneleri\" in wiki_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"türkiye\" in wiki_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"futbol\" in wiki_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3850"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"türkiye\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Fake Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Türkiye bir\"\n",
    "# TEXT = \"Temmuz ayı içerisinde\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Türkiye bir ▁zamanlar ▁xxmaj ▁türkiye ' yi ▁oluşturan ▁xxmaj ▁kuzey ▁xxmaj ▁kıbrıs ▁xxmaj ▁türk ▁xxmaj ▁cumhuriyeti ' nden ▁sonra ▁en ▁büyük ▁ikinci ▁ülke dir . ▁xxmaj ▁türkiye ' nin ▁hiçbir ▁bölümünde ▁xxmaj ▁türkiye ' ye ▁bağlı ▁olmayan ▁xxmaj ▁türkiye ' nin ▁de\n",
      "Türkiye bir ▁ilk e ▁imza ▁atması ▁xxmaj ▁türkiye ' de ▁ilk ▁kez ▁bir iktir ilmektedir . ▁xxmaj ▁bu ▁olayı ▁\" üç lü ▁xxmaj ▁türkiye ▁ - ▁\" kırı m ▁xxmaj ▁ yor tus u \" ▁ - ▁xxmaj ▁i ̇ stanbul ▁xxmaj\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Türkiye bir ▁xxmaj ▁türk ▁vatandaşı dır . ▁xxmaj ▁türkiye ' de ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş ▁xxmaj ▁savaşı ' nın ▁ilk ▁yıllarında ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş ▁xxmaj ▁savaşı ' nın ▁en ▁önemli ▁askeri ▁ve ▁askeri ▁gücü ▁olan ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş ▁xxmaj ▁savaşı\n",
      "Türkiye bir ▁xxmaj ▁türk ▁xxmaj ▁cumhuriyeti ' dir . ▁xxmaj ▁türkiye ' nin ▁xxmaj ▁türkiye ' ye ▁ilk ▁kez ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş ▁xxmaj ▁savaşı ' nda ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş ▁xxmaj ▁savaşı ' nda ▁yenilmesi nden ▁sonra ▁xxmaj ▁türk ▁xxmaj ▁kurtuluş\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Türkiye'de kadın olmak\"\n",
    "# TEXT = \"Temmuz ayı içerisinde\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Türkiye'de kadın olmak ▁üzere ▁toplam ▁2 79 ▁kadın ▁ve ▁4 59 ▁kadın ▁olmak ▁üzere ▁toplam ▁12 3 ▁kadın ▁bu ▁görev le ▁ülkeyi ▁temsil ▁etmeye ▁başladı . ▁xxmaj ▁ ma tur i yan ▁xxmaj ▁okuma ▁xxmaj ▁ocağı ' nda ▁( şimdiki ▁xxmaj ▁türkiye ▁xxmaj\n",
      "Türkiye'de kadın olmak ▁üzere ▁4 ▁ayrı ▁şahıs tan ▁oluşan ▁bir ▁ekip ▁bulunmaktadır . ▁xxmaj ▁türkiye ▁xxmaj ▁i ̇ şçi ▁xxmaj ▁partisi ▁ile ▁xxmaj ▁türkiye ▁xxmaj ▁büyük ▁xxmaj ▁millet ▁xxmaj ▁meclisi , ▁xxmaj ▁bakanlar ▁xxmaj ▁kurulu , ▁xxmaj ▁i ̇ ş ▁xxmaj ▁i ̇\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Türkiye Almanya ilişkileri her zaman\"\n",
    "# TEXT = \"Temmuz ayı içerisinde\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Türkiye Almanya ilişkileri her zaman ▁önemli ▁bir ▁rol ▁oynamıştır . ▁xxmaj ▁türkiye , ▁xxmaj ▁türkiye ' nin ▁altı ▁ülkesinde n ▁biridir . ▁xxmaj ▁türkiye , ▁xxmaj ▁fransa ' nın ▁bir ▁parçası ▁olup ▁xxmaj ▁fransa ' nın ▁karşılık sız ▁olarak ▁başkenti ▁xxmaj ▁brüksel ' dir .\n",
      "Türkiye Almanya ilişkileri her zaman ▁sağlam ▁ve ▁yavaş ken , ▁xxmaj ▁türkiye ▁xxmaj ▁cumhuriyeti , ▁xxmaj ▁türkiye ' nin ▁bu ▁sınırları ▁içerisinde ▁bulunan ▁üç ▁büyük ▁xxmaj ▁türkiye ' yi kapa dığı ▁bir ▁sırada ▁xxmaj ▁almanya ' nın ▁bir ▁parçası ▁olmuştur . ▁xxmaj ▁türkiye ' nin\n",
      "Türkiye Almanya ilişkileri her zaman ▁daha ▁belirgin dir . ▁xxmaj ▁türkiye ' de ▁xxmaj ▁ankara ' nın ▁xxmaj ▁türkiye ' ye ▁ait ▁olmasından ▁yararlanılarak ▁kurulan ▁xxmaj ▁ankara ▁xxmaj ▁veteriner ▁xxmaj ▁bölümü , ▁xxmaj ▁türkiye ' deki ▁en ▁önemli ▁spor ▁dalları ▁arasındadır . ▁xxmaj ▁türkiye '\n",
      "Türkiye Almanya ilişkileri her zaman ▁tek ▁bir ▁ülke ▁tarafından ▁yönetil mekteydi . ▁< ▁/ ▁doc > ▁xxbos ▁xxmaj ▁ er ya man ▁xxmaj ▁ er ya man , ▁xxmaj ▁ankara ▁ilinin ▁xxmaj ▁ er gan i ▁ilçesine ▁bağlı ▁bir ▁köydür . ▁xxmaj ▁ er ya\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.win.tue.nl/~mpechen/projects/smm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/.fastai/data/trwiki')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ec2-user/.fastai/data/trwiki/trmoviesentiment/tr_polarity.pos'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/trmoviesentiment/Turkish_Movie_Sentiment.zip'),\n",
       " PosixPath('/home/ec2-user/.fastai/data/trwiki/trmoviesentiment/tr_polarity.neg')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_clas = path/'trmoviesentiment'\n",
    "path_clas.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerçekten harika bir yapim birçok kez izledim ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her izledigimde hayranlik duydugum gerçek klas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerçekten tarihi savas filmleri arasinda tarti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aldigi ödülleri sonuna dek hak eden muhtesem b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özgürlük denilince aklima gelen ilk film.bir b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos\n",
       "0  gerçekten harika bir yapim birçok kez izledim ...    1\n",
       "1  her izledigimde hayranlik duydugum gerçek klas...    1\n",
       "2  gerçekten tarihi savas filmleri arasinda tarti...    1\n",
       "3  aldigi ödülleri sonuna dek hak eden muhtesem b...    1\n",
       "4  özgürlük denilince aklima gelen ilk film.bir b...    1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = (path_clas/'tr_polarity.pos').open(encoding='iso-8859-9').readlines()\n",
    "pos_df = pd.DataFrame({'text':pos})\n",
    "pos_df['pos'] = 1\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giseye oynayan bir film.mel gibson'in oyunculu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bircok yonden sahip olduklari zayifliklari pop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995 ten bu yana bu tür filmler artti , o zama...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mel gibson tam bir ingiliz düsmani her filmind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milliyetçi bir film tavsiye etmiyorum.... \\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos\n",
       "0  giseye oynayan bir film.mel gibson'in oyunculu...    0\n",
       "1  bircok yonden sahip olduklari zayifliklari pop...    0\n",
       "2  1995 ten bu yana bu tür filmler artti , o zama...    0\n",
       "3  mel gibson tam bir ingiliz düsmani her filmind...    0\n",
       "4       milliyetçi bir film tavsiye etmiyorum.... \\n    0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = (path_clas/'tr_polarity.neg').open(encoding='iso-8859-9').readlines()\n",
    "neg_df = pd.DataFrame({'text':neg})\n",
    "neg_df['pos'] = 0\n",
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pos_df,neg_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py:475: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ds.items = np.array(sum(e.map(self._encode_batch, partition_by_cores(ds.items, self.n_cpus)), []))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_df(df, path_clas, cols='text', processor=SPProcessor.load(dest))\n",
    "    .split_by_rand_pct(0.1, seed=42)\n",
    "    .label_for_lm()           \n",
    "    .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "# data_lm.save(f'{lang}_clas_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save(f'{lang}_clas_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path_clas, f'{lang}_clas_databunch', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sa ▁bile ▁sinema ▁olgusu nun ▁en ▁üst ▁noktalar in dan . . ▁xxbos ▁gerçekten ▁tarihi ▁sav as ▁filmleri ▁ara si nda ▁tar tis ma siz ▁en ▁iyi si ▁ , ▁12 ▁ yi l ▁boyunca ▁ac aba ▁ikincisi ▁çek ir imi ▁diye ▁bekledi gim ▁bir ▁film ▁ , bel ki ▁william ▁wallace ▁baba sinin ▁ölümünden ▁sonra ▁amca si ▁yani na ▁al mis ti ▁onu ▁ ye tis tir mis ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>le ni siyle ▁insana ▁ iste ▁film ▁böyle ▁çekilir ▁de dir ten ▁kusur suz ▁bir ▁film . ▁xxbos ▁böyle ▁güzel ▁bir ▁yap it ▁olamaz ▁filmde ▁her ▁sey ▁var ▁insani ▁dünya dan ▁ali p ▁götür üyor ▁bask a ▁diya r lara ▁film ▁bitti kten ▁sonra ▁epey ▁süre ▁geçmesi ▁gerekiyor ▁tekrar ▁dünya ▁ya ▁dönmek ▁için ▁dikkat ! . ▁xxbos ▁ in an ir mi siniz ▁bu ▁filmi ▁ ne ▁kadar ▁izledi gi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁wallace  in ▁i sk ence ▁edilerek ▁idam ▁edilmesi . . . ve ▁sonunda ▁özgürlük ▁diye ▁hay kir isi . . . ha lan ▁ unu ta mi yorum ▁xxrep ▁4 ▁ . ▁xxbos ▁ilk ▁bu ▁filmi ▁sinema da ▁izledi m ▁ve ▁insan in ▁ in an di ktan ▁sonra ▁ ne leri ▁yap a bile ce gi ni ▁fark ▁etti m . ▁gerçekten ▁süper ▁film di . ▁halen ▁içi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁uzun lug una ▁al dan ip ta ▁filmi ▁izlemek ten ▁vazgeçme yin ▁xxrep ▁4 ▁ . ▁xxbos ▁harika ▁bir ▁film di ▁xxrep ▁5 ▁ . ▁xxbos ▁mükemmel ▁ ötesi . . ▁ . ▁xxbos ▁hiç ▁ a bart mi yorum ▁hayat im da ▁izledi gim ▁en ▁iyi ▁film lerden ▁biri ▁diye bilir im . tam ▁bir ▁bas yap it ▁nitel ig inde . o scar ▁al di gina ▁hiç ▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁filmlerinden ▁biri . ▁diyalog lar ▁çok ▁iyi . ▁kesinlikle ▁izlenmesi ▁gereken ▁bir ▁film . . ▁xxbos ▁tarantino nun ▁bu ▁filmi ▁kendini ▁belli ▁etti r iyor . hat ta ▁ben ce ▁tarantino nun ▁en ▁iyi ▁filmidir . kendi ne ▁has ▁ anlat imi ▁ile ▁bu ▁film ▁hak ka ten ▁sinema ▁sever lerin ▁izlemesi ▁gereken ▁bir ▁film . ben ▁10 ▁üzerinden ▁7 ▁verdi m ▁bu ▁benim ▁için ▁oldukça ▁çok ▁puan . ▁xxbos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s3 backup HBA\n",
    "s3://<folder>-ml/trlanguagemodel/models/\n",
    "\n",
    "`\n",
    "(base) $ aws s3 ls s3://<folder>-ml/trlanguagemodel/models/\n",
    "2020-10-31 21:16:33  387655145 learner_mod_tr_spm_save.pkl.pth\n",
    "2020-10-31 21:16:33  131193699 learner_modtr_spm.pkl\n",
    "2020-10-31 21:16:33  129098532 learner_tr_spm_enc.pth\n",
    "2020-10-31 21:16:33     577263 learner_vocab_tr_spm.pkl\n",
    "2020-10-31 21:16:33  129219117 tr_wt.pth\n",
    "2020-10-31 21:16:33     577263 tr_wt_vocab.pkl\n",
    "`\n",
    "\n",
    "`\n",
    "s3://[golder]-ml/trlanguagemodel/docs/tr_databunch\n",
    "`\n",
    "\n",
    "`\n",
    "(base)  $ aws s3 ls s3://[folder]-ml/trmoviesentiment/models/\n",
    "2020-10-31 21:34:11  387655273 trfine_tuned.pth\n",
    "2020-10-31 21:34:11  129098532 trfine_tuned_enc.pth\n",
    "2020-10-31 21:46:14  170109634 trclas.pth\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, pretrained_fnames=lm_fns, drop_mult=1.0, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.784773</td>\n",
       "      <td>4.122668</td>\n",
       "      <td>0.308103</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.130692</td>\n",
       "      <td>3.965839</td>\n",
       "      <td>0.329911</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.984847</td>\n",
       "      <td>3.865781</td>\n",
       "      <td>0.343036</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.760760</td>\n",
       "      <td>3.796683</td>\n",
       "      <td>0.354554</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.524284</td>\n",
       "      <td>3.779068</td>\n",
       "      <td>0.361429</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.303044</td>\n",
       "      <td>3.793252</td>\n",
       "      <td>0.364420</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(5, slice(lr/10,lr*10), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save(f'{lang}fine_tuned')\n",
    "learn_lm.save_encoder(f'{lang}fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages/fastai/text/data.py:475: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ds.items = np.array(sum(e.map(self._encode_batch, partition_by_cores(ds.items, self.n_cpus)), []))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.env/fastai/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "data_clas = (TextList.from_df(df, path_clas, cols='text', processor=SPProcessor.load(dest))\n",
    "    .split_by_rand_pct(0.1, seed=42)\n",
    "    .label_from_df(cols='pos')\n",
    "    .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, pretrained=False, wd=0.1).to_fp16()\n",
    "learn_c.load_encoder(f'{lang}fine_tuned_enc')\n",
    "learn_c.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-2\n",
    "lr *= bs/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>6.122978</td>\n",
       "      <td>0.484991</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.445498</td>\n",
       "      <td>0.367657</td>\n",
       "      <td>0.842402</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.freeze_to(-2)\n",
    "learn_c.fit_one_cycle(2, slice(lr/(2.6**4),lr), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.372276</td>\n",
       "      <td>0.521453</td>\n",
       "      <td>0.791745</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.348258</td>\n",
       "      <td>0.305345</td>\n",
       "      <td>0.869606</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c.freeze_to(-3)\n",
    "learn_c.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.324016</td>\n",
       "      <td>0.318310</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.271153</td>\n",
       "      <td>0.891182</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.269719</td>\n",
       "      <td>0.256308</td>\n",
       "      <td>0.898687</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252074</td>\n",
       "      <td>0.255850</td>\n",
       "      <td>0.900563</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c.unfreeze()\n",
    "learn_c.fit_one_cycle(4, slice(lr/10/(2.6**4),lr/10), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy in Gezici (2018), *Sentiment Analysis in Turkish* is: `75.16%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c.save(f'{lang}clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
